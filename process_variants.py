### PYTHON SCRIPT 2 (AFTER DEEPVARIANT) ###

import os
import yaml
import re
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, wait, as_completed
import pandas as pd
import time
import numpy as np
import subprocess
from itertools import cycle
import argparse
import glob
import gzip
from os.path import basename, join
import sys
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.colors import ListedColormap

### Determine the full path of which minigene_splicing_assay dir was copied to ###
minigene_dir = os.path.dirname(os.path.realpath(__file__))

### Load config.yaml ###
config_file = os.path.join(minigene_dir, "minigene_config.yaml")
with open(config_file, 'r') as f:
    config = yaml.safe_load(f)

###  Assign variables from minigene_config.yaml ###
root_output_dir = config["root_output_dir"]
mut_region_start = config["mut_region_start"]
mut_region_end = config["mut_region_end"]
failed_variants = config["failed_variants"]
max_workers = config["max_workers"]

### define and create directories ###
base_output_dir = os.path.join(root_output_dir, "variant_barcode_results")
deepvariant_dir = os.path.join(base_output_dir, "deepvariant")
post_process_variants_dir = os.path.join(base_output_dir, "postprocess_variants")
if not os.path.exists(post_process_variants_dir):
    os.makedirs(post_process_variants_dir)

def read_process_vcf(file_path):
    """
    Reads and processes a *vcf.gz file generated by DeepVariant, extracting relevant data and adding a BARCODE column

    Parameters: 
    * file_path (str): Path to *.vcf.gz file

    Returns:
    * df containing the processed VCF data with "BARCODE", "CHROM", "POS", "ID", "REF", "ALT", "QUAL", "FILTER", "INFO", "FORMAT" and "default" columns

    Workflow:
    * Define column names and initialize a list to store data rows
    * Open the *.vcf.gz file in read mode with gzip
    * Process VCF File Lines:
        - Skip lines starting with '##' (metadata)
        - Parse the header line (starting with '#')
        - Process data lines, extract relevant columns, and prepend the barcode
    * Convert the list of data rows into a df with predefined columns
    """
    columns = ["BARCODE", "CHROM", "POS", "ID", "REF", "ALT", "QUAL", "FILTER", "INFO", "FORMAT", "default"]
    data_rows = []
    with gzip.open(file_path, 'rt') as file:
        for line in file:
            if line.startswith('##'):
                continue
            elif line.startswith('#'):
                header_line = line.lstrip('#').strip().split('\t')
            else:
                data_line = line.strip().split('\t')
                barcode = basename(file_path).replace('.vcf.gz', '')
                data_rows.append([barcode] + data_line[:10])
    df = pd.DataFrame(data_rows, columns=columns)
    return df

def process_vcf(deepvariant_dir):
    """
    Extract and filters variant info from *.vcf.gz files before saving the results to CSV and text files

    Parameters:
    -----------
    deepvariant_dir (str): Path to the directory containing the *.vcf.gz files
    """
    ### identify all *.vcf.gz files in the specified directory, excluding files ending with .g.vcf.gz ###
    file_pattern = os.path.join(deepvariant_dir, "**/*.vcf.gz")
    file_paths = glob.glob(file_pattern, recursive=True)
    vcf_files = [file for file in file_paths if not file.endswith('.g.vcf.gz')]

    ### read and process *.vcf.gz files in parallel and store all resulting dfs in a list ###
    dfs = []
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        ### submit all tasks to the executor ###
        futures = [executor.submit(read_process_vcf, file_path) for file_path in vcf_files]
        for future in futures:
            dfs.append(future.result())

    ### concat all dfs and filter ###
    final_df = pd.concat(dfs, ignore_index=True)
    final_df = final_df[final_df['FILTER'] == 'PASS']                                                                           ### only keep variant calls that pass ###
    final_df = final_df[final_df['REF'].str.len() == 1]                                                                         ### account for only substitutions ###
    final_df = final_df[final_df['ALT'].str.len() == 1]
    final_df = final_df.drop(columns=['ID', 'INFO', 'FORMAT', 'FILTER', 'CHROM'])                                               ### drop unnecessary columns ###
    final_df['VARIANT'] = final_df.apply(lambda row: f"{row['POS']}{row['REF']}>{row['ALT']}", axis=1)                          ### ceate a VARIANT column that contains SNV information ###
    final_df = final_df[['BARCODE', 'POS', 'REF', 'ALT','VARIANT', 'QUAL', 'default']]
    final_df.rename(columns={'QUAL': 'VARIANT_QUAL', 'default': 'VARIANT_ALLELIC_DEPTH'}, inplace=True)
    final_df["VARIANT_ALLELIC_DEPTH"] = final_df["VARIANT_ALLELIC_DEPTH"].str.split(':').str[3].str.split(',').str[1]           ### extract variant allelic depth from 'default' column ###
    final_df['POS'] = final_df['POS'].astype(int)

    ### separate out variants found outside mutagenesis region in non_mut_df ###
    non_mut_df = final_df[(final_df['POS'] < mut_region_start) | (final_df['POS'] > mut_region_end)]                            ### filter df for variants with 'POS' found outside mutagenesis region ###
    non_mut_df = non_mut_df[["BARCODE", "VARIANT", "VARIANT_QUAL", "VARIANT_ALLELIC_DEPTH"]]
    non_mut_df = non_mut_df.groupby('VARIANT').agg({
        'BARCODE': [('BARCODES', lambda x: ','.join(x)),                                                                        ### concat all barcodes associate with specific variant and split by ',' ###
                    ('UNIQUE_BARCODE_COUNT', 'nunique')],                                                                       ### count number of unique barcodes per variant ###
                    'VARIANT_QUAL': [('VARIANT_QUAL', lambda x: ','.join(x.astype(str)))],                                      ### concat all quality scores of variant called per barcode.bam and split by ',' ###
                    'VARIANT_ALLELIC_DEPTH': [('VARIANT_ALLELIC_DEPTH', lambda x: ','.join(x.astype(str)))]                     ### concat all variant allelic depths per barcode.bam and split by ',' ###
                    }).reset_index()
    non_mut_df.columns = ['VARIANT', 'BARCODE', 'UNIQUE_BARCODE_COUNT', 'VARIANT_QUAL', 'VARIANT_ALLELIC_DEPTH']
    non_mut_df = non_mut_df[['VARIANT', 'BARCODE', 'UNIQUE_BARCODE_COUNT', 'VARIANT_ALLELIC_DEPTH', 'VARIANT_QUAL', 'VARIANT_ALLELIC_DEPTH']]
    non_mut_df = non_mut_df[(non_mut_df['UNIQUE_BARCODE_COUNT'] > 0)]
    non_mut_df = non_mut_df.reset_index(drop=True)

    ### separate out variants found within mutagenesis region in mut_df ###
    mut_df = final_df[(final_df['POS'] >= mut_region_start) & (final_df['POS'] <= mut_region_end)]                              ### filter df for variants in mutagenesis region ###
    mut_df = mut_df[["BARCODE", "VARIANT", "VARIANT_QUAL", "VARIANT_ALLELIC_DEPTH"]]
    mut_df = mut_df.groupby('VARIANT').agg({
        'BARCODE': [('BARCODES', lambda x: ','.join(x)),
                    ('UNIQUE_BARCODE_COUNT', 'nunique')],
                    'VARIANT_QUAL': [('VARIANT_QUAL', lambda x: ','.join(x.astype(str)))],
                    'VARIANT_ALLELIC_DEPTH': [('VARIANT_ALLELIC_DEPTH', lambda x: ','.join(x.astype(str)))]
                    }).reset_index()
    mut_df.columns = ['VARIANT', 'BARCODE', 'UNIQUE_BARCODE_COUNT', 'VARIANT_QUAL', 'VARIANT_ALLELIC_DEPTH']
    mut_df = mut_df[['VARIANT', 'BARCODE', 'UNIQUE_BARCODE_COUNT', 'VARIANT_ALLELIC_DEPTH', 'VARIANT_QUAL']]
    mut_df = mut_df[(mut_df['UNIQUE_BARCODE_COUNT'] > 0)]
    mut_df = mut_df.reset_index(drop=True)

    ### clean 'mut_df' and 'non_mut_df' ###
    mut_df['BARCODE'] = mut_df['BARCODE'].apply(lambda x: x.split(','))                                                         ### splits each string in mut_df and non_mut_df's 'BARCODE' column at every ',' to give a list of substrings ###
    mut_df['VARIANT_QUAL'] = mut_df['VARIANT_QUAL'].apply(lambda x: [float(q) for q in x.split(',')])                                           ### transforms mut_df[]'QUAL'] from a single string with comma-separated numerical values into a list of float values ###
    mut_df['VARIANT_ALLELIC_DEPTH'] = mut_df['VARIANT_ALLELIC_DEPTH'].apply(lambda x: [int(q) for q in x.split(',')])           ### transforms mut_df['VARIANT_ALLELIC_DEPTH'] from a single string with comma-separated numerical values into a list of integer values ###

    non_mut_df['BARCODE'] = non_mut_df['BARCODE'].apply(lambda x: x.split(','))

    ### iterate over each row in non_mut_df ###
    for _, non_mut_row in non_mut_df.iterrows():
        non_mut_barcodes = non_mut_row['BARCODE']
        for index, mut_row in mut_df.iterrows():
            mut_barcodes = mut_row['BARCODE']
            mut_qual = mut_row['VARIANT_QUAL']
            mut_AD = mut_row['VARIANT_ALLELIC_DEPTH']

            ### removes barcodes found in both mut_df and non_mut_df from mut_df ###
            updated_barcodes = []
            updated_qual = []
            updated_AD = []
            for i, barcode in enumerate(mut_barcodes):
                if barcode not in non_mut_barcodes:
                    updated_barcodes.append(barcode)
                    updated_qual.append(mut_qual[i])
                    updated_AD.append(mut_AD[i])

            ### update the row only if there are changes ###
            if len(updated_barcodes) != len(mut_barcodes):
                mut_df.at[index, 'BARCODE'] = updated_barcodes
                mut_df.at[index, 'VARIANT_QUAL'] = updated_qual
                mut_df.at[index, 'UNIQUE_BARCODE_COUNT'] = len(updated_barcodes)
                mut_df.at[index, 'VARIANT_ALLELIC_DEPTH'] = updated_AD

    ### filter out rows where mut_df['COUNT']=0 ###
    updated_mut_df = mut_df[mut_df['UNIQUE_BARCODE_COUNT'] > 0]

    ### convert 'BARCODE' and 'VARIANT_QUAL' lists back to comma-separated strings ###
    updated_mut_df['BARCODE'] = updated_mut_df['BARCODE'].apply(lambda x: ','.join(x))
    updated_mut_df['VARIANT_QUAL'] = updated_mut_df['VARIANT_QUAL'].apply(lambda x: ','.join([str(q) for q in x]))

    ### calculate 'TOTAL_VARIANT_ALLELIC_DEPTH' by summing up all 'VARIANT_ALLELIC_DEPTH' values (AD per barcode) ###
    updated_mut_df['TOTAL_VARIANT_ALLELIC_DEPTH'] = updated_mut_df['VARIANT_ALLELIC_DEPTH'].apply(lambda x: sum(x))

    conditions = updated_mut_df["VARIANT"].isin(failed_variants)
    updated_mut_df = updated_mut_df[~conditions]
    updated_mut_df = updated_mut_df.reset_index(drop=True)
    updated_mut_df['VARIANT_ALLELIC_DEPTH'] = updated_mut_df['VARIANT_ALLELIC_DEPTH'].apply(lambda x: ', '.join(map(str, x)))
    updated_mut_df_path = os.path.join(post_process_variants_dir, "codon_barcodes_all_info.csv")
    updated_mut_df.to_csv(updated_mut_df_path, index=False)
    main_updated_mut_df = updated_mut_df[["VARIANT", "BARCODE", "UNIQUE_BARCODE_COUNT", "TOTAL_VARIANT_ALLELIC_DEPTH", "VARIANT_QUAL"]]
    main_updated_mut_df_path = os.path.join(post_process_variants_dir, "SNV_barcode_info.csv")
    main_updated_mut_df.to_csv(main_updated_mut_df_path, index=False)
   
    ### extract non-unique and unique barcodes and save to non_unique_barcode.txt and barcode.txt file respectively ###
    barcodes = updated_mut_df['BARCODE'].str.split(',').explode()

    ### find barcodes that are tagged to >1 variant i.e. non_unique barcodes ###
    barcode_counts = barcodes.value_counts()
    non_unique_barcodes = barcode_counts[barcode_counts > 1].index

    ### save non-unique barcodes to non_unique_barcode.txt file ###
    non_unique_barcode_txt_path = os.path.join(post_process_variants_dir, "non_unique_SNV_barcodes.txt")
    with open(non_unique_barcode_txt_path, 'w') as f:
        for barcode in non_unique_barcodes:
            f.write(f"{barcode}\n")

    ### filter out non-unique barcodes from list of all unique barcodes ###
    unique_barcodes = barcodes[~barcodes.isin(non_unique_barcodes)]

    ### save remaining unique barcodes to barcode.txt file ###
    barcode_txt_path = os.path.join(post_process_variants_dir, "unique_SNV_barcodes.txt")
    unique_barcodes.to_csv(barcode_txt_path, index=False, header=False)

    return main_updated_mut_df

def plot_SNV_plots(main_updated_mut_df):
    """
    Plots two heatmaps, one visualising depths of SNVs and the other, number of unique barcodes associated with each SNV, 
    which are saved in SNV_depths_plots.pdf

    Parameters:
    * main_updated_mut_df (df): df containing SNV info including unique barcode counts and variant depths

    Workflow:
    1. Heatmaps Data Preparation
        * extracts relevant columns from main_updated_mut_df ("VARIANT", "UNIQUE_BARCODE_COUNT", "TOTAL_VARIANT_ALLELIC_DEPTH")
        * calls nested add_ref_to_variant function to add reference variants 
        * extracts position, reference base, and observed base from each SNV
    2. Heatmap of SNV Depths
        * visualises SNV depths with x-axis as SNV's positions and y-axis as SNV's observed base, including blue overlays for reference bases 
    3. Heatmap of Unique Barcode Counts
        * visualises number of unique barcodes associated with each SNV with x-axis as SNV's positions and y-axis as SNV's observed base, including blue overlays for reference bases 
    4. Outputs SNV_depths_plots.pdf with both heatmaps
    """
    main_updated_mut_df = main_updated_mut_df[["VARIANT", "UNIQUE_BARCODE_COUNT", "TOTAL_VARIANT_ALLELIC_DEPTH"]]

    ### Function to add a row where VARIANT is {position}{ref}>{ref} without duplicates ###
    def add_ref_to_variant(main_updated_mut_df):
        """
        Nested function to add reference information to main_updated_mut_df to be plotted out later in heatmaps

        Parameters:
        * main_updated_mut_df (df): df containing SNV info including unique barcode counts and variant depths

        Workflow:
        * Iterates through each row in main_updated_mut_df to extract the SNV's position and reference base
        * Constructs a new variant string in the format {position}{ref_base}>{ref_base}
        * Checks if the newly created reference variant already exists in main_updated_mut_df or newly created rows (seen_variants). If not, it adds a new row with this reference variant and default values
        * Outputs modified df including all original rows and newly added reference variants 
        """
        new_rows = []
        seen_variants = set(main_updated_mut_df['VARIANT'])                                                                     ### track variants already seen (original + newly added) ###
        
        ### loop through each row in main_updated_mut_df ###
        for index, row in main_updated_mut_df.iterrows():
            variant = row['VARIANT']
            
            position = ''.join(filter(str.isdigit, variant))                                                                    ### extract SNV's position ###
            ref_base = variant.split('>')[0][-1]                                                                                ### extract SNV's reference base ###

            ### create the new variant {position}{ref_base}>{ref_base} ###
            ref_variant = f"{position}{ref_base}>{ref_base}"

            ### check if the row already exists in main_updated_mut_df or in new rows ###
            if ref_variant not in seen_variants:
                new_rows.append({'VARIANT': ref_variant, 'UNIQUE_BARCODE_COUNT': 0, 'TOTAL_VARIANT_ALLELIC_DEPTH': 0})          ### add 0 for 'UNIQUE_BARCODE_COUNT' and 'TOTAL_VARIANT_ALLELIC_DEPTH' for ref ###
                seen_variants.add(ref_variant)                                                                                  ### mark this variant as seen ###

        ### Create a df for new rows and append it to the original main_updated_mut_df and concat ###
        new_main_updated_mut_df = pd.DataFrame(new_rows)
        main_updated_mut_df = pd.concat([main_updated_mut_df, new_main_updated_mut_df], ignore_index=True)

        return main_updated_mut_df                                                                                            

    ### call add_ref_to_variant to main_updated_mut_df to add reference bases ###
    main_updated_mut_df = add_ref_to_variant(main_updated_mut_df)                                               

    ### create new columns "POSITION", "REF_BASE" and "OBS_BASE" based on "VARIANT"
    main_updated_mut_df["POSITION"] = main_updated_mut_df["VARIANT"].str.extract(r'(\d+)')
    main_updated_mut_df["REF_BASE"] = main_updated_mut_df["VARIANT"].apply(lambda x: x.split('>')[0][-1])
    main_updated_mut_df["OBS_BASE"] = main_updated_mut_df["VARIANT"].apply(lambda x: x.split('>')[1])
    main_updated_mut_df = main_updated_mut_df[["VARIANT", "POSITION", "REF_BASE", "OBS_BASE", "UNIQUE_BARCODE_COUNT", "TOTAL_VARIANT_ALLELIC_DEPTH"]]
    main_updated_mut_df.sort_values(by='POSITION', inplace=True)

    ### create pdf file to store plots ###
    with PdfPages(os.path.join(root_output_dir, "variant_barcode_results", "postprocess_variants", "SNV_depths_plots.pdf")) as pdf:
        ### SNV depth heatmap ###

        ### pivot the data for depth_heatmap ###
        depth_heatmap_data = main_updated_mut_df.pivot(index="OBS_BASE", columns="POSITION", values="TOTAL_VARIANT_ALLELIC_DEPTH")

        ### determine the minimum and maximum depth values for heatmap's color bar ###
        min_depth = main_updated_mut_df['TOTAL_VARIANT_ALLELIC_DEPTH'].min()
        max_depth = main_updated_mut_df['TOTAL_VARIANT_ALLELIC_DEPTH'].max()

        ### create custom colormap ###
        cmap = sns.cubehelix_palette(dark=.25, light=.75, as_cmap=True)                                                         ### varying intensities of pink-purple for present variants ###
        blue_cmap = ListedColormap(["#BBCEF0"])                                                                                 ### light blue for reference bases ###

        ### create full range of positions within mutagenesis region  for x-axis tick labels ###
        full_depth_range = list(range(mut_region_start, mut_region_end+1))

        ### reindex depth_heatmap_data to ensure all positions within mutagenesis region are included ###
        depth_heatmap_data = depth_heatmap_data.reindex(columns=map(str, full_depth_range))

        ### recreate the mask after reindexing to match the shape of depth_heatmap_data ###
        mask = (depth_heatmap_data == 0)

        ### plot the heatmap ###
        plt.figure(figsize=(50, 8))  
        ax = sns.heatmap(depth_heatmap_data, cmap=cmap, annot=False, 
                        cbar_kws={'label': 'SNV Depth', 'orientation': 'horizontal', 'location': 'bottom', 'pad': 0.3, 'shrink': 0.5, 'anchor': (1, 0)}, 
                        mask=mask, vmin=min_depth, vmax=max_depth)

        ### 0verlay the blue heatmap for reference bases ###
        sns.heatmap(depth_heatmap_data, cmap=blue_cmap, mask=~mask, cbar=False, ax=ax)

        ### configure colorbar of heatmap ###
        depth_cbar = ax.collections[0].colorbar                                                                                 ### get the colorbar object ###
        depth_cbar.ax.tick_params(labelsize=15, rotation=90)                                                                    ### set tick label size and rotation ###
        depth_cbar_ticks = list(range(min_depth, max_depth, 1000))                                                              ### set tick range and intervals ###
        depth_cbar.set_ticks(depth_cbar_ticks)
        depth_cbar.set_label("Variant Read Depths", fontsize=20, labelpad=10)                                                   ### set colorbar label size ###

        ### create custom legend handles with rectangular shapes and outlines ###
        blue_legend = [plt.Line2D([0], [0], marker="s", color="#BBCEF0", markersize=49, markeredgecolor="black", markeredgewidth=0.5, linestyle='None')]
        white_legend = [plt.Line2D([0], [0], marker="s", color="white", markersize=49, markeredgecolor="black", markeredgewidth=0.5, linestyle='None')]
        labels = ["Reference Bases", "Variants Not Found"]
        handles = blue_legend + white_legend
        plt.legend(handles, labels, loc="lower center", bbox_to_anchor=(0.58, -0.83), ncols=2, frameon=False, fontsize=20, columnspacing=3)  

        ### configure heatmap ticks on both x and y axes ###
        tick_positions = range(len(full_depth_range)) 
        adjusted_tick_positions = [pos + 0.43 for pos in tick_positions] 
        ax.set_xticks(adjusted_tick_positions)  
        ax.set_xticklabels(full_depth_range, rotation=90, fontsize=11, ha='left')
        ax.tick_params(axis='x', which='major', tick1On=True, tick2On=False, pad=1.5)
        ax.tick_params(axis='y', which='major', tick1On=False, tick2On=False, pad=0)
        plt.yticks(rotation=0, fontsize=20)

        ### configure title and axes labels ###
        plt.title("Heatmap of SNV Depths", fontsize=50, pad=50)
        plt.xlabel("Position", fontsize=30, labelpad=30)
        plt.ylabel("Observed Base", fontsize=30, labelpad=30)

        plt.subplots_adjust(left=0.03, right=0.99, top=0.8, bottom=0.15)

        pdf.savefig()
        plt.close()

        ### SNV barcode heatmap ###

        ### pivot the data for barcode_heatmap ###
        barcode_heatmap_data = main_updated_mut_df.pivot(index="OBS_BASE", columns="POSITION", values="UNIQUE_BARCODE_COUNT")

        ### Determine the minimum and maximum count values for heatmap's color bar ###
        min_count = main_updated_mut_df['UNIQUE_BARCODE_COUNT'].min()
        max_count = main_updated_mut_df['UNIQUE_BARCODE_COUNT'].max()

        ### create custom colormap for present variants and reference bases ###
        cmap = sns.cubehelix_palette(dark=.25, light=.75, as_cmap=True)
        blue_cmap = ListedColormap(["#BBCEF0"])

        ### create the full range of positions within mutagenesis region for x-axis tick labels ###
        full_count_range = list(range(mut_region_start, mut_region_end+1))

        ### reindex the barcode_heatmap_data to ensure all positions within mutagenesis region are included ###
        barcode_heatmap_data = barcode_heatmap_data.reindex(columns=map(str, full_count_range))

        ### recreate the mask after reindexing to match the shape of barcode_heatmap_data ###
        mask = (barcode_heatmap_data == 0)

        ### Plot the heatmap ###
        plt.figure(figsize=(50, 8)) 
        ax = sns.heatmap(barcode_heatmap_data, cmap=cmap, annot=False, 
                        cbar_kws={'label': 'SNV Depth', 'orientation': 'horizontal', 'location': 'bottom', 'pad': 0.3, 'shrink': 0.5, 'anchor': (1, 0)}, 
                        mask=mask, vmin=min_count, vmax=max_count)

        ### overlay the blue heatmap for reference bases ###
        sns.heatmap(barcode_heatmap_data, cmap=blue_cmap, mask=~mask, cbar=False, ax=ax)

        ### configure colorbar of barcode count heatmap ###
        count_cbar = ax.collections[0].colorbar  
        count_cbar.ax.tick_params(labelsize=15) 
        count_cbar_ticks = list(range(min_count, max_count, 5))
        count_cbar.set_ticks(count_cbar_ticks)
        count_cbar.set_label("Number of Unique Barcodes per SNV", fontsize=20, labelpad=10) 

        ### create custom legend handles with rectangular shapes and outlines ###
        blue_legend = [plt.Line2D([0], [0], marker="s", color="#BBCEF0", markersize=49, markeredgecolor="black", markeredgewidth=0.5, linestyle='None')]
        white_legend = [plt.Line2D([0], [0], marker="s", color="white", markersize=49, markeredgecolor="black", markeredgewidth=0.5, linestyle='None')]
        labels = ["Reference Bases", "Variants Not Found"]
        handles = blue_legend + white_legend
        plt.legend(handles, labels, loc="lower center", bbox_to_anchor=(0.58, -0.83), ncols=2, frameon=False, fontsize=20, columnspacing=3)  

        ### configure x and y axes tick labels ###
        tick_positions = range(len(full_count_range)) 
        adjusted_tick_positions = [pos + 0.43 for pos in tick_positions]
        ax.set_xticks(adjusted_tick_positions) 
        ax.set_xticklabels(full_count_range, rotation=90, fontsize=11, ha='left')
        ax.tick_params(axis='x', which='major', tick1On=True, tick2On=False, pad=1.5)
        ax.tick_params(axis='y', which='major', tick1On=False, tick2On=False, pad=0)
        plt.yticks(rotation=0, fontsize=20)

        ### configure title and axes labels ###
        plt.title("Heatmap of Unique Barcode Counts per SNV", fontsize=50, pad=50)
        plt.xlabel("Position", fontsize=30, labelpad=30)
        plt.ylabel("Observed Base", fontsize=30, labelpad=30)

        plt.subplots_adjust(left=0.03, right=0.99, top=0.8, bottom=0.15)

        pdf.savefig()
        plt.close()

### flag file to remove ###
def remove_flag_file(root_output_dir, flag_filename="initial_setup_done.flag"):
    flag_path = os.path.join(root_output_dir, "variant_barcode_results", flag_filename)
    if os.path.exists(flag_path):
        os.remove(flag_path)
    else:
        print(f"{flag_path} does not exist - nothing to remove.")

def main():
    main_updated_mut_df = process_vcf(deepvariant_dir)
    plot_SNV_plots(main_updated_mut_df)
    remove_flag_file(root_output_dir)

if __name__ == "__main__":
    main()
